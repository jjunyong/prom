# Istio + Kubernetes 1.20.8 환경 Prometheus/Grafana 모니터링 완전 설치 가이드

## ⚠️ Kubernetes 1.20.8 호환성 정보
- **Kubernetes**: 1.20.8
- **kube-prometheus-stack**: 45.31.1 (K8s 1.20 호환 버전)
- **Prometheus Operator**: 0.56.3
- **Grafana**: 8.5.27
- **API 버전 변경사항**: CronJob은 `batch/v1beta1` 사용

## 📋 목차
1. [사전 준비사항](#1-사전-준비사항)
2. [디렉토리 구조 생성](#2-디렉토리-구조-생성)
3. [네임스페이스 생성](#3-네임스페이스-생성)
4. [Prometheus + Grafana 설치](#4-prometheus--grafana-설치)
5. [Spring Boot 애플리케이션 설정](#5-spring-boot-애플리케이션-설정)
6. [ServiceMonitor 설정](#6-servicemonitor-설정)
7. [CronJob 모니터링 설정](#7-cronjob-모니터링-설정)
8. [Grafana 대시보드 설정](#8-grafana-대시보드-설정)
9. [Alert Rules 설정](#9-alert-rules-설정)
10. [설치 검증](#10-설치-검증)
11. [트러블슈팅](#11-트러블슈팅)

---

## 1. 사전 준비사항

### 필수 도구 확인
```bash
# Kubernetes 버전 확인 (1.20.8)
kubectl version --short
# 출력 예시: Client Version: v1.20.x / Server Version: v1.20.8

# Helm 3 설치 확인 (없으면 설치)
helm version

# Helm 3 설치 (필요시)
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

# Istio 설치 확인
kubectl get pods -n istio-system

# API 버전 확인 (중요!)
kubectl api-versions | grep batch
# batch/v1
# batch/v1beta1  <- CronJob에 이 버전 사용
```

---

## 2. 디렉토리 구조 생성

```bash
# 프로젝트 디렉토리 생성
mkdir -p kia-monitoring/{config,dashboards,alerts}
cd kia-monitoring

# 디렉토리 구조
# kia-monitoring/
# ├── config/
# │   ├── 01-namespace.yaml
# │   ├── 02-prometheus-values-k8s-1.20.yaml
# │   ├── 03-servicemonitor.yaml
# │   ├── 04-pushgateway.yaml
# │   └── 05-spring-deployment.yaml
# ├── dashboards/
# │   ├── kia-main-dashboard.json
# │   └── configmap-dashboard.yaml
# └── alerts/
#     └── alert-rules.yaml
```

---

## 3. 네임스페이스 생성

### Step 3.1: 네임스페이스 YAML 생성
```bash
cat > config/01-namespace.yaml <<'EOF'
apiVersion: v1
kind: Namespace
metadata:
  name: monitoring
  labels:
    name: monitoring
    istio-injection: enabled
EOF
```

### Step 3.2: 네임스페이스 적용
```bash
kubectl apply -f config/01-namespace.yaml

# 확인
kubectl get namespace monitoring
```

---

## 4. Prometheus + Grafana 설치 (K8s 1.20.8 호환 버전)

### Step 4.1: Helm Repository 추가
```bash
# Prometheus Community Helm Chart 추가
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo add stable https://charts.helm.sh/stable
helm repo update

# K8s 1.20 호환 버전 확인
helm search repo prometheus-community/kube-prometheus-stack --versions | grep -E "45\.|44\.|43\."
```

### Step 4.2: Prometheus + Grafana 설정 파일 생성 (K8s 1.20.8 전용)
```bash
cat > config/02-prometheus-values-k8s-1.20.yaml <<'EOF'
# Kubernetes 1.20.8 호환 설정
fullnameOverride: prometheus

# 버전 고정 (K8s 1.20 호환)
prometheusOperator:
  image:
    tag: v0.56.3  # K8s 1.20 호환 버전
  admissionWebhooks:
    enabled: false  # K8s 1.20에서 webhook 이슈 방지
    
# Prometheus 설정
prometheus:
  prometheusSpec:
    image:
      tag: v2.35.0  # K8s 1.20 호환 버전
    
    # 데이터 보존 기간
    retention: 30d
    retentionSize: "50GB"
    
    # 스토리지 설정
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: "standard"  # 클러스터에 맞게 수정
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 100Gi
    
    # 리소스 설정
    resources:
      requests:
        cpu: 1000m
        memory: 2Gi
      limits:
        cpu: 2000m
        memory: 4Gi
    
    # 스크레이프 간격
    scrapeInterval: 30s
    evaluationInterval: 30s
    
    # ServiceMonitor 셀렉터
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false
    
    # 추가 스크레이프 설정
    additionalScrapeConfigs:
    # Istio 메트릭 수집
    - job_name: 'istio-mesh'
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - istio-system
      relabel_configs:
      - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: istio-telemetry;prometheus
    
    # Spring Boot 애플리케이션 메트릭 수집
    - job_name: 'spring-boot-pods'
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - source_labels: [__meta_kubernetes_namespace]
        target_label: namespace
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
      - source_labels: [__meta_kubernetes_pod_label_app]
        target_label: app
    
    # PushGateway 메트릭 수집 (CronJob용)
    - job_name: 'pushgateway'
      static_configs:
      - targets: ['prometheus-pushgateway:9091']

# Grafana 설정
grafana:
  enabled: true
  
  # Grafana 버전 (K8s 1.20 호환)
  image:
    tag: 8.5.27
  
  # 관리자 계정
  adminUser: admin
  adminPassword: "KiaMonitoring2024!"
  
  # 리소스 설정
  resources:
    limits:
      cpu: 1000m
      memory: 2Gi
    requests:
      cpu: 500m
      memory: 1Gi
  
  # 영구 스토리지
  persistence:
    enabled: true
    storageClassName: "standard"  # 클러스터에 맞게 수정
    size: 10Gi
  
  # 서비스 설정
  service:
    type: LoadBalancer  # 또는 NodePort
    port: 80
  
  # 데이터소스 자동 설정
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: Prometheus
        type: prometheus
        url: http://prometheus-prometheus:9090
        access: proxy
        isDefault: true
        jsonData:
          timeInterval: "30s"
  
  # 대시보드 자동 프로비저닝
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: 'KIA'
        type: file
        disableDeletion: false
        updateIntervalSeconds: 10
        allowUiUpdates: true
        options:
          path: /var/lib/grafana/dashboards/default
  
  # 기본 대시보드 활성화
  defaultDashboardsEnabled: true
  
  # 추가 플러그인 설치
  plugins:
    - grafana-piechart-panel
    - grafana-clock-panel
    - grafana-worldmap-panel
  
  # Sidecar 설정 (ConfigMap에서 대시보드 자동 로드)
  sidecar:
    dashboards:
      enabled: true
      label: grafana_dashboard
      folder: /tmp/dashboards
      provider:
        allowUiUpdates: true
    datasources:
      enabled: true
      defaultDatasourceEnabled: true

# AlertManager 설정
alertmanager:
  enabled: true
  alertmanagerSpec:
    image:
      tag: v0.24.0  # K8s 1.20 호환 버전
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: "standard"
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
  config:
    global:
      resolve_timeout: 5m
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'null'
      routes:
      - match:
          severity: critical
        receiver: slack-critical
    receivers:
    - name: 'null'
    - name: 'slack-critical'
      slack_configs:
      - api_url: 'YOUR_SLACK_WEBHOOK_URL'  # Slack Webhook URL 입력
        channel: '#alerts'
        title: 'KIA.com Critical Alert'

# K8s 1.20에서는 일부 기능 비활성화
kubeApiServer:
  enabled: true
kubeControllerManager:
  enabled: false  # K8s 1.20에서 권한 이슈 방지
kubeScheduler:
  enabled: false  # K8s 1.20에서 권한 이슈 방지
kubeEtcd:
  enabled: false
kubeProxy:
  enabled: false  # K8s 1.20에서 권한 이슈 방지
kubeStateMetrics:
  enabled: true
nodeExporter:
  enabled: true

# K8s 1.20 호환성을 위한 추가 설정
commonLabels:
  kubernetes_version: "1.20.8"
EOF
```

### Step 4.3: Helm으로 설치 (K8s 1.20 호환 버전)
```bash
# K8s 1.20 호환 버전으로 설치 (45.31.1)
helm install prometheus-stack \
  prometheus-community/kube-prometheus-stack \
  --version 45.31.1 \
  --namespace monitoring \
  --create-namespace \
  -f config/02-prometheus-values-k8s-1.20.yaml

# 설치 상태 확인
helm list -n monitoring

# Pod 상태 확인 (모든 pod이 Running 상태가 될 때까지 대기)
kubectl get pods -n monitoring -w

# 만약 에러가 발생하면 이전 버전 시도
# helm install prometheus-stack \
#   prometheus-community/kube-prometheus-stack \
#   --version 43.3.1 \
#   --namespace monitoring \
#   -f config/02-prometheus-values-k8s-1.20.yaml
```

---

## 5. Spring Boot 애플리케이션 설정

### Step 5.1: Spring Boot application.yaml 설정
```yaml
# src/main/resources/application.yaml
spring:
  application:
    name: kia-api-service

management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus,metrics
      base-path: /actuator
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: ${spring.application.name}
      environment: production
      service: kia-web
  endpoint:
    prometheus:
      enabled: true
    health:
      show-details: always
      probes:
        enabled: true

# 서버 포트 설정
server:
  port: 8080
  
# Actuator 포트 분리 (선택사항)
management:
  server:
    port: 8081
```

### Step 5.2: Spring Boot Deployment YAML 생성
```bash
cat > config/05-spring-deployment.yaml <<'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-dpl
  namespace: default
  labels:
    app: api-dpl
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-dpl
  template:
    metadata:
      labels:
        app: api-dpl
        version: v1
      annotations:
        # Prometheus 스크레이핑 설정
        prometheus.io/scrape: "true"
        prometheus.io/port: "8081"
        prometheus.io/path: "/actuator/prometheus"
        # Istio 사이드카 주입
        sidecar.istio.io/inject: "true"
    spec:
      containers:
      - name: api-service
        image: kia/api-service:latest  # 실제 이미지로 변경
        ports:
        - containerPort: 8080
          name: http
          protocol: TCP
        - containerPort: 8081
          name: metrics
          protocol: TCP
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "production"
        - name: JAVA_OPTS
          value: "-Xmx1024m -Xms512m -XX:+UseG1GC"
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8081
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
  name: api-dpl-service
  namespace: default
  labels:
    app: api-dpl
spec:
  type: ClusterIP
  ports:
  - port: 8080
    name: http
    targetPort: 8080
    protocol: TCP
  - port: 8081
    name: metrics
    targetPort: 8081
    protocol: TCP
  selector:
    app: api-dpl
EOF

# 적용
kubectl apply -f config/05-spring-deployment.yaml
```

---

## 6. ServiceMonitor 설정

### Step 6.1: ServiceMonitor YAML 생성
```bash
cat > config/03-servicemonitor.yaml <<'EOF'
# Spring Boot 애플리케이션 모니터링
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: spring-boot-api
  namespace: monitoring
  labels:
    app: api-dpl
    release: prometheus-stack
spec:
  namespaceSelector:
    matchNames:
    - default
  selector:
    matchLabels:
      app: api-dpl
  endpoints:
  - port: metrics
    interval: 30s
    path: /actuator/prometheus
    scheme: http
---
# Istio 메트릭 모니터링
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: istio-mesh-metrics
  namespace: monitoring
  labels:
    release: prometheus-stack
spec:
  namespaceSelector:
    matchNames:
    - istio-system
  selector:
    matchLabels:
      app: istio-telemetry
  endpoints:
  - port: prometheus
    interval: 30s
---
# Istio Ingress Gateway 모니터링
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: istio-ingressgateway
  namespace: monitoring
  labels:
    release: prometheus-stack
spec:
  namespaceSelector:
    matchNames:
    - istio-system
  selector:
    matchLabels:
      app: istio-ingressgateway
  endpoints:
  - port: http-envoy-prom
    interval: 30s
    path: /stats/prometheus
EOF

# 적용
kubectl apply -f config/03-servicemonitor.yaml
```

---

## 7. CronJob 모니터링 설정 (K8s 1.20.8)

### Step 7.1: PushGateway 설치
```bash
cat > config/04-pushgateway.yaml <<'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus-pushgateway
  namespace: monitoring
  labels:
    app: prometheus-pushgateway
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus-pushgateway
  template:
    metadata:
      labels:
        app: prometheus-pushgateway
    spec:
      containers:
      - name: pushgateway
        image: prom/pushgateway:v1.4.3  # K8s 1.20 호환 버전
        ports:
        - containerPort: 9091
          name: metrics
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        livenessProbe:
          httpGet:
            path: /-/healthy
            port: 9091
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /-/ready
            port: 9091
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus-pushgateway
  namespace: monitoring
  labels:
    app: prometheus-pushgateway
spec:
  type: ClusterIP
  ports:
  - port: 9091
    targetPort: 9091
    name: metrics
  selector:
    app: prometheus-pushgateway
EOF

kubectl apply -f config/04-pushgateway.yaml
```

### Step 7.2: CronJob 예제 (K8s 1.20.8용 - batch/v1beta1)
```bash
cat > config/cronjob-example.yaml <<'EOF'
# K8s 1.20.8에서는 batch/v1beta1 사용
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: batch-job-daily-report
  namespace: default
spec:
  schedule: "0 2 * * *"  # 매일 새벽 2시
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            job_name: daily-report
        spec:
          containers:
          - name: batch-job
            image: kia/batch-job:latest
            command:
            - /bin/bash
            - -c
            - |
              # 작업 시작 시간 기록
              START_TIME=$(date +%s)
              JOB_NAME="daily-report"
              
              # 실제 배치 작업 실행
              echo "Starting batch job: $JOB_NAME"
              java -jar /app/batch.jar --job.name=dailyReport
              JOB_STATUS=$?
              
              # 작업 종료 시간 및 소요시간 계산
              END_TIME=$(date +%s)
              DURATION=$((END_TIME - START_TIME))
              
              # PushGateway로 메트릭 전송
              cat <<EOT | curl --data-binary @- http://prometheus-pushgateway.monitoring:9091/metrics/job/cronjob/instance/${JOB_NAME}
              # TYPE batch_job_duration_seconds gauge
              batch_job_duration_seconds{job_name="${JOB_NAME}"} ${DURATION}
              # TYPE batch_job_last_success_timestamp gauge
              batch_job_last_success_timestamp{job_name="${JOB_NAME}"} ${END_TIME}
              # TYPE batch_job_status gauge
              batch_job_status{job_name="${JOB_NAME}"} ${JOB_STATUS}
              EOT
              
              echo "Batch job completed with status: $JOB_STATUS"
              exit $JOB_STATUS
          restartPolicy: OnFailure
EOF

kubectl apply -f config/cronjob-example.yaml
```

---

## 8. Grafana 대시보드 설정 (계속)

# Kubernetes 1.20.8 모니터링 가이드 - Part 2

## 8. Grafana 대시보드 설정 (계속)

### Step 8.1: 커스텀 대시보드 JSON 파일 생성
```bash
cat > dashboards/kia-main-dashboard.json <<'EOF'
{
  "annotations": {
    "list": [
      {
        "builtIn": 1,
        "datasource": "-- Grafana --",
        "enable": true,
        "hide": true,
        "iconColor": "rgba(0, 211, 255, 1)",
        "name": "Annotations & Alerts",
        "type": "dashboard"
      }
    ]
  },
  "editable": true,
  "gnetId": null,
  "graphTooltip": 1,
  "id": null,
  "links": [],
  "panels": [
    {
      "datasource": "Prometheus",
      "description": "현재 서비스 가용성",
      "fieldConfig": {
        "defaults": {
          "color": {
            "mode": "thresholds"
          },
          "mappings": [],
          "max": 100,
          "min": 0,
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {"color": "red", "value": null},
              {"color": "yellow", "value": 95},
              {"color": "green", "value": 99}
            ]
          },
          "unit": "percent"
        }
      },
      "gridPos": {"h": 8, "w": 6, "x": 0, "y": 0},
      "id": 1,
      "options": {
        "orientation": "auto",
        "reduceOptions": {
          "calcs": ["lastNotNull"],
          "fields": "",
          "values": false
        },
        "showThresholdLabels": false,
        "showThresholdMarkers": true
      },
      "pluginVersion": "8.5.27",
      "targets": [
        {
          "expr": "avg(up{job=\"spring-boot-pods\",app=\"api-dpl\"}) * 100",
          "legendFormat": "Availability",
          "refId": "A"
        }
      ],
      "title": "서비스 가용성 (SLA)",
      "type": "gauge"
    },
    {
      "datasource": "Prometheus",
      "description": "초당 요청 처리량",
      "fieldConfig": {
        "defaults": {
          "color": {"mode": "palette-classic"},
          "custom": {
            "axisLabel": "",
            "axisPlacement": "auto",
            "barAlignment": 0,
            "drawStyle": "line",
            "fillOpacity": 10,
            "gradientMode": "none",
            "hideFrom": {
              "legend": false,
              "tooltip": false,
              "viz": false
            },
            "lineInterpolation": "linear",
            "lineWidth": 2,
            "pointSize": 5,
            "scaleDistribution": {"type": "linear"},
            "showPoints": "never",
            "spanNulls": true,
            "stacking": {"group": "A", "mode": "none"},
            "thresholdsStyle": {"mode": "off"}
          },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [{"color": "green", "value": null}]
          },
          "unit": "reqps"
        }
      },
      "gridPos": {"h": 8, "w": 12, "x": 6, "y": 0},
      "id": 2,
      "options": {
        "legend": {
          "calcs": ["mean", "max"],
          "displayMode": "table",
          "placement": "bottom"
        },
        "tooltip": {"mode": "single"}
      },
      "targets": [
        {
          "expr": "sum(rate(istio_request_total{destination_service_namespace=\"default\",destination_service_name=\"api-dpl-service\"}[5m]))",
          "legendFormat": "Request Rate",
          "refId": "A"
        }
      ],
      "title": "요청 처리율 (RPS)",
      "type": "timeseries"
    },
    {
      "datasource": "Prometheus",
      "description": "P95 응답시간",
      "fieldConfig": {
        "defaults": {
          "color": {"mode": "thresholds"},
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              {"color": "green", "value": null},
              {"color": "yellow", "value": 500},
              {"color": "red", "value": 1000}
            ]
          },
          "unit": "ms"
        }
      },
      "gridPos": {"h": 8, "w": 6, "x": 18, "y": 0},
      "id": 3,
      "options": {
        "colorMode": "value",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": ["lastNotNull"],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "targets": [
        {
          "expr": "histogram_quantile(0.95, sum(rate(istio_request_duration_milliseconds_bucket{destination_service_namespace=\"default\"}[5m])) by (le))",
          "legendFormat": "P95",
          "refId": "A"
        }
      ],
      "title": "P95 응답시간",
      "type": "stat"
    }
  ],
  "refresh": "30s",
  "schemaVersion": 30,
  "style": "dark",
  "tags": ["kia", "production"],
  "templating": {"list": []},
  "time": {"from": "now-1h", "to": "now"},
  "timepicker": {},
  "timezone": "Asia/Seoul",
  "title": "KIA.com 메인 대시보드",
  "uid": "kia-main",
  "version": 1,
  "weekStart": ""
}
EOF
```

### Step 8.2: ConfigMap으로 대시보드 배포
```bash
cat > dashboards/configmap-dashboard.yaml <<'EOF'
apiVersion: v1
kind: ConfigMap
metadata:
  name: kia-dashboard
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  kia-dashboard.json: |
    {
      "dashboard": {
        "title": "KIA Web Service Dashboard",
        "panels": [],
        "refresh": "30s",
        "time": {"from": "now-1h", "to": "now"}
      }
    }
EOF

kubectl apply -f dashboards/configmap-dashboard.yaml
```

### Step 8.3: Grafana 접속 및 대시보드 Import

```bash
# Grafana 접속 정보 확인
echo "===== Grafana 접속 정보 ====="
echo "URL: http://localhost:3000"
echo "Username: admin"
echo "Password: KiaMonitoring2024!"

# Port-forward 설정
kubectl port-forward -n monitoring svc/prometheus-stack-grafana 3000:80
```

**브라우저에서 대시보드 Import:**
1. http://localhost:3000 접속
2. 로그인 (admin / KiaMonitoring2024!)
3. 좌측 메뉴 → Dashboards → Import
4. 다음 Dashboard ID 입력:
   - `7636` : Istio Service Mesh Dashboard
   - `12900` : Spring Boot 2.1 Statistics
   - `4701` : JVM (Micrometer)
   - `8588` : Kubernetes Cluster Monitoring (K8s 1.20 호환)
5. 또는 위에서 생성한 `kia-main-dashboard.json` 파일 업로드

---

## 9. Alert Rules 설정

### Step 9.1: Alert Rules YAML 생성
```bash
cat > alerts/alert-rules.yaml <<'EOF'
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kia-web-alerts
  namespace: monitoring
  labels:
    prometheus: kube-prometheus
    role: alert-rules
    release: prometheus-stack  # Helm release 이름과 일치
spec:
  groups:
  - name: kia.web.sla
    interval: 30s
    rules:
    # 높은 에러율 알림
    - alert: HighErrorRate
      expr: |
        (sum(rate(istio_request_total{destination_service_namespace="default",response_code=~"5.."}[5m])) 
        / sum(rate(istio_request_total{destination_service_namespace="default"}[5m]))) > 0.01
      for: 5m
      labels:
        severity: critical
        service: kia-web
        team: platform
      annotations:
        summary: "높은 에러율 감지 ({{ $value | humanizePercentage }})"
        description: "지난 5분간 에러율이 1%를 초과했습니다. 현재: {{ $value | humanizePercentage }}"
    
    # 높은 응답시간 알림
    - alert: HighLatency
      expr: |
        histogram_quantile(0.95,
          sum(rate(istio_request_duration_milliseconds_bucket{destination_service_namespace="default"}[5m])) 
          by (le)
        ) > 1000
      for: 5m
      labels:
        severity: warning
        service: kia-web
        team: platform
      annotations:
        summary: "높은 응답시간 감지"
        description: "P95 응답시간이 1초를 초과했습니다. 현재: {{ $value }}ms"
    
    # 서비스 다운 알림
    - alert: ServiceDown
      expr: up{job="spring-boot-pods",app="api-dpl"} == 0
      for: 2m
      labels:
        severity: critical
        service: kia-api
        team: platform
      annotations:
        summary: "서비스 다운"
        description: "{{ $labels.pod }} 파드가 2분 이상 다운 상태입니다."
    
    # 메모리 사용량 알림
    - alert: HighMemoryUsage
      expr: |
        (sum(jvm_memory_used_bytes{application="kia-api-service",area="heap"}) 
        / sum(jvm_memory_max_bytes{application="kia-api-service",area="heap"})) > 0.85
      for: 5m
      labels:
        severity: warning
        service: kia-api
        team: platform
      annotations:
        summary: "높은 메모리 사용량"
        description: "JVM 힙 메모리 사용량이 85%를 초과했습니다. 현재: {{ $value | humanizePercentage }}"
    
    # 배치 작업 실패 알림
    - alert: BatchJobFailed
      expr: batch_job_status != 0
      for: 1m
      labels:
        severity: warning
        service: batch
        team: data
      annotations:
        summary: "배치 작업 실패"
        description: "{{ $labels.job_name }} 배치 작업이 실패했습니다. 상태 코드: {{ $value }}"
    
    # 배치 작업 지연 알림
    - alert: BatchJobDelayed
      expr: |
        (time() - batch_job_last_success_timestamp) > 7200
      for: 5m
      labels:
        severity: warning
        service: batch
        team: data
      annotations:
        summary: "배치 작업 지연"
        description: "{{ $labels.job_name }} 작업이 2시간 이상 실행되지 않았습니다."
    
    # DB 연결 풀 고갈 알림
    - alert: DatabaseConnectionPoolExhausted
      expr: |
        (hikaricp_connections_active{application="kia-api-service"} 
        / hikaricp_connections_max{application="kia-api-service"}) > 0.9
      for: 3m
      labels:
        severity: critical
        service: database
        team: platform
      annotations:
        summary: "DB 연결 풀 고갈 임박"
        description: "데이터베이스 연결 풀 사용량이 90%를 초과했습니다. 현재: {{ $value | humanizePercentage }}"
    
    # Pod 재시작 알림
    - alert: PodRestartingTooOften
      expr: |
        rate(kube_pod_container_status_restarts_total{namespace="default",pod=~"api-dpl-.*"}[1h]) > 0.5
      for: 5m
      labels:
        severity: warning
        service: kia-api
        team: platform
      annotations:
        summary: "Pod 빈번한 재시작"
        description: "{{ $labels.pod }} Pod이 시간당 0.5회 이상 재시작되고 있습니다."
EOF

kubectl apply -f alerts/alert-rules.yaml
```

---

## 10. 설치 검증

### Step 10.1: 전체 시스템 검증 스크립트
```bash
cat > verify-installation.sh <<'EOF'
#!/bin/bash

echo "======================================"
echo "KIA 모니터링 시스템 설치 검증"
echo "Kubernetes 버전: 1.20.8"
echo "======================================"

# 색상 정의
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

# 함수: 상태 체크
check_status() {
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}✓${NC} $1"
    else
        echo -e "${RED}✗${NC} $1"
        return 1
    fi
}

# 0. Kubernetes 버전 확인
echo -e "\n${YELLOW}0. Kubernetes 버전 확인${NC}"
SERVER_VERSION=$(kubectl version --short 2>/dev/null | grep "Server Version" | awk '{print $3}')
echo "Server Version: $SERVER_VERSION"
if [[ "$SERVER_VERSION" == *"1.20"* ]]; then
    echo -e "${GREEN}✓${NC} Kubernetes 1.20.x 확인됨"
else
    echo -e "${YELLOW}!${NC} Kubernetes 버전이 1.20.x가 아닙니다. 호환성 문제가 있을 수 있습니다."
fi

# 1. Namespace 확인
echo -e "\n${YELLOW}1. Namespace 확인${NC}"
kubectl get namespace monitoring > /dev/null 2>&1
check_status "monitoring namespace 존재"

# 2. Prometheus 확인
echo -e "\n${YELLOW}2. Prometheus 상태${NC}"
kubectl get pod -n monitoring -l app.kubernetes.io/name=prometheus -o wide
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=prometheus -n monitoring --timeout=60s > /dev/null 2>&1
check_status "Prometheus Pod 실행중"

# 3. Grafana 확인
echo -e "\n${YELLOW}3. Grafana 상태${NC}"
kubectl get pod -n monitoring -l app.kubernetes.io/name=grafana -o wide
kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=grafana -n monitoring --timeout=60s > /dev/null 2>&1
check_status "Grafana Pod 실행중"

# 4. PushGateway 확인
echo -e "\n${YELLOW}4. PushGateway 상태${NC}"
kubectl get pod -n monitoring -l app=prometheus-pushgateway -o wide
kubectl wait --for=condition=ready pod -l app=prometheus-pushgateway -n monitoring --timeout=60s > /dev/null 2>&1
check_status "PushGateway Pod 실행중"

# 5. ServiceMonitor 확인
echo -e "\n${YELLOW}5. ServiceMonitor 설정${NC}"
kubectl get servicemonitor -n monitoring
check_status "ServiceMonitor 생성됨"

# 6. PrometheusRule 확인
echo -e "\n${YELLOW}6. Alert Rules 설정${NC}"
kubectl get prometheusrule -n monitoring
check_status "PrometheusRule 생성됨"

# 7. API Deployment 확인
echo -e "\n${YELLOW}7. Spring Boot API 상태${NC}"
kubectl get deployment api-dpl -n default > /dev/null 2>&1
if [ $? -eq 0 ]; then
    kubectl get pod -n default -l app=api-dpl
    check_status "API Deployment 실행중"
else
    echo -e "${YELLOW}! API Deployment가 아직 배포되지 않았습니다${NC}"
fi

# 8. CronJob 확인 (K8s 1.20에서는 batch/v1beta1)
echo -e "\n${YELLOW}8. CronJob 상태 (batch/v1beta1)${NC}"
kubectl get cronjob -n default > /dev/null 2>&1
if [ $? -eq 0 ]; then
    kubectl get cronjob -n default
    check_status "CronJob 확인됨"
else
    echo -e "${YELLOW}! CronJob이 아직 생성되지 않았습니다${NC}"
fi

# 9. 서비스 접속 정보
echo -e "\n${YELLOW}9. 서비스 접속 정보${NC}"
echo "======================================"
GRAFANA_SVC=$(kubectl get svc -n monitoring prometheus-stack-grafana -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null)
if [ -z "$GRAFANA_SVC" ]; then
    echo "Grafana: kubectl port-forward -n monitoring svc/prometheus-stack-grafana 3000:80"
    echo "         http://localhost:3000"
else
    echo "Grafana: http://$GRAFANA_SVC"
fi
echo "Username: admin"
echo "Password: KiaMonitoring2024!"
echo ""
echo "Prometheus: kubectl port-forward -n monitoring svc/prometheus-prometheus 9090:9090"
echo "           http://localhost:9090"
echo ""
echo "PushGateway: kubectl port-forward -n monitoring svc/prometheus-pushgateway 9091:9091"
echo "            http://localhost:9091"
echo "======================================"

# 10. Metrics 수집 테스트
echo -e "\n${YELLOW}10. Metrics 수집 테스트${NC}"
kubectl port-forward -n monitoring svc/prometheus-prometheus 9090:9090 > /dev/null 2>&1 &
PF_PID=$!
sleep 3

# Prometheus targets 확인
curl -s http://localhost:9090/api/v1/targets 2>/dev/null | jq '.data.activeTargets | length' > /dev/null 2>&1
if [ $? -eq 0 ]; then
    TARGET_COUNT=$(curl -s http://localhost:9090/api/v1/targets 2>/dev/null | jq '.data.activeTargets | length')
    echo -e "${GREEN}✓${NC} Active targets: $TARGET_COUNT"
else
    echo -e "${YELLOW}! Prometheus API 접속 실패 (port-forward 필요)${NC}"
fi

kill $PF_PID 2>/dev/null

# 11. Helm 설치 상태
echo -e "\n${YELLOW}11. Helm 설치 상태${NC}"
helm list -n monitoring
helm status prometheus-stack -n monitoring 2>/dev/null | grep "STATUS:" | head -1

echo -e "\n${GREEN}설치 검증 완료!${NC}"
echo "======================================"
echo "K8s 1.20.8 호환 모니터링 스택 준비 완료"
echo "======================================"
EOF

chmod +x verify-installation.sh
./verify-installation.sh
```

---

## 11. 트러블슈팅 (K8s 1.20.8 특화)

### K8s 1.20.8 특유 문제 해결

#### API 버전 관련 에러
```bash
# CronJob API 버전 확인
kubectl api-resources | grep -i cronjob
# batch/v1beta1   true         CronJob

# 만약 batch/v1 사용 시 에러가 나면 batch/v1beta1로 변경
sed -i 's/apiVersion: batch\/v1/apiVersion: batch\/v1beta1/g' *.yaml
```

#### Webhook 에러 (K8s 1.20)
```bash
# ValidatingWebhookConfiguration 에러 시
kubectl delete validatingwebhookconfiguration prometheus-stack-kube-prom-admission 2>/dev/null
kubectl delete mutatingwebhookconfiguration prometheus-stack-kube-prom-admission 2>/dev/null
```

#### RBAC 권한 에러
```bash
# ServiceAccount 권한 추가
cat <<EOF | kubectl apply -f -
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus-monitoring
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: prometheus-prometheus
  namespace: monitoring
EOF
```

#### Pod이 Pending 상태일 때
```bash
# PVC 상태 확인
kubectl get pvc -n monitoring

# StorageClass 확인 및 수정
kubectl get storageclass
# 기본 StorageClass가 없으면 생성
kubectl patch storageclass <your-storage-class> -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'

# 이벤트 확인
kubectl describe pod <pod-name> -n monitoring
```

#### 메트릭이 수집되지 않을 때
```bash
# Prometheus targets 확인
kubectl port-forward -n monitoring svc/prometheus-prometheus 9090:9090
# 브라우저에서 http://localhost:9090/targets 확인

# ServiceMonitor 레이블 확인
kubectl get servicemonitor -n monitoring -o yaml | grep -A5 "selector:"

# Pod 어노테이션 확인
kubectl get pod api-dpl-xxx -n default -o yaml | grep -A5 "annotations:"

# Prometheus 설정 리로드
kubectl rollout restart statefulset/prometheus-prometheus -n monitoring
```

#### Grafana 대시보드가 비어있을 때
```bash
# 데이터소스 확인
kubectl exec -n monitoring deployment/prometheus-stack-grafana -- \
  curl -s http://admin:KiaMonitoring2024!@localhost:3000/api/datasources

# Prometheus 쿼리 테스트
kubectl port-forward -n monitoring svc/prometheus-prometheus 9090:9090
# http://localhost:9090/graph 에서 쿼리 테스트
# 예: up{job="spring-boot-pods"}
```

#### 로그 확인
```bash
# Prometheus 로그
kubectl logs -n monitoring -l app.kubernetes.io/name=prometheus --tail=100

# Grafana 로그
kubectl logs -n monitoring -l app.kubernetes.io/name=grafana --tail=100

# Prometheus Operator 로그
kubectl logs -n monitoring -l app.kubernetes.io/component=controller --tail=100

# Spring Boot 앱 로그
kubectl logs -n default -l app=api-dpl --tail=100
```

### Helm 관련 문제 해결

#### Helm 업그레이드 (설정 변경 시)
```bash
# values 파일 수정 후 업그레이드
helm upgrade prometheus-stack \
  prometheus-community/kube-prometheus-stack \
  --version 45.31.1 \
  -n monitoring \
  -f config/02-prometheus-values-k8s-1.20.yaml

# 롤백이 필요한 경우
helm rollback prometheus-stack -n monitoring
```

#### 완전 재설치
```bash
# 1. 기존 설치 삭제
helm uninstall prometheus-stack -n monitoring

# 2. CRD 삭제 (필요시)
kubectl delete crd prometheuses.monitoring.coreos.com
kubectl delete crd prometheusrules.monitoring.coreos.com
kubectl delete crd servicemonitors.monitoring.coreos.com
kubectl delete crd podmonitors.monitoring.coreos.com
kubectl delete crd alertmanagers.monitoring.coreos.com
kubectl delete crd thanosrulers.monitoring.coreos.com

# 3. 재설치
helm install prometheus-stack \
  prometheus-community/kube-prometheus-stack \
  --version 45.31.1 \
  -n monitoring \
  -f config/02-prometheus-values-k8s-1.20.yaml
```

---

## 🎯 K8s 1.20.8 설치 완료 체크리스트

- [ ] Kubernetes 1.20.8 버전 확인
- [ ] Monitoring namespace 생성됨
- [ ] Prometheus Stack v45.31.1 설치 완료
- [ ] 모든 Pod이 Running 상태
- [ ] Grafana 접속 가능
- [ ] ServiceMonitor 생성됨
- [ ] Alert Rules 설정됨
- [ ] PushGateway 실행중
- [ ] Spring Boot 메트릭 수집 확인
- [ ] Istio 메트릭 수집 확인
- [ ] CronJob (batch/v1beta1) 동작 확인
- [ ] 대시보드 Import 완료

---

## 📚 K8s 1.20.8 관련 참고 자료

- [Kubernetes 1.20 Release Notes](https://kubernetes.io/blog/2020/12/08/kubernetes-1-20-release-announcement/)
- [Prometheus Operator Compatibility](https://github.com/prometheus-operator/prometheus-operator#compatibility)
- [kube-prometheus-stack Version Matrix](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack#upgrading-chart)

---

## 💡 K8s 1.20.8 환경 최적화 팁

1. **API 버전 주의사항**
   - CronJob: `batch/v1beta1` 사용
   - Ingress: `networking.k8s.io/v1beta1` 사용
   - ValidatingWebhookConfiguration: 비활성화 권장

2. **리소스 제한**
   - Prometheus: 메모리 2Gi 이하 권장
   - Grafana: 메모리 1Gi로 충분

3. **보안 설정**
   - PodSecurityPolicy 대신 RBAC 활용
   - NetworkPolicy 설정 권장

4. **성능 최적화**
   - scrapeInterval: 30s (기본값 유지)
   - retention: 30d (디스크 공간 고려)

---

## 빠른 설치 명령어 모음

```bash
# 전체 설치 스크립트
cat > quick-install.sh <<'EOF'
#!/bin/bash
echo "KIA.com K8s 1.20.8 모니터링 스택 설치 시작..."

# 1. 디렉토리 생성
mkdir -p kia-monitoring/{config,dashboards,alerts}
cd kia-monitoring

# 2. 네임스페이스 생성
kubectl create namespace monitoring

# 3. Helm repo 추가
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# 4. Prometheus Stack 설치 (K8s 1.20.8 호환)
helm install prometheus-stack \
  prometheus-community/kube-prometheus-stack \
  --version 45.31.1 \
  --namespace monitoring \
  --set prometheusOperator.admissionWebhooks.enabled=false \
  --set kubeControllerManager.enabled=false \
  --set kubeScheduler.enabled=false \
  --set kubeProxy.enabled=false \
  --set grafana.adminPassword="KiaMonitoring2024!"

# 5. 설치 확인
echo "설치 완료. Pod 상태 확인중..."
kubectl get pods -n monitoring

echo "Grafana 접속: kubectl port-forward -n monitoring svc/prometheus-stack-grafana 3000:80"
echo "Username: admin / Password: KiaMonitoring2024!"
EOF

chmod +x quick-install.sh
./quick-install.sh
```

---

**작성일**: 2024년
**Kubernetes 버전**: 1.20.8
**버전**: 2.0 (K8s 1.20.8 호환)
**작성자**: KIA DevOps Team
